{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03a9cf1-973d-42aa-aa10-678a3117c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n"
     ]
    }
   ],
   "source": [
    "print(\"Running\")\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9447d20-90ab-45fe-9b65-2a2bc6b10100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SinusoidalMLPPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim=128):\n",
    "        \"\"\"\n",
    "        Sinusoidal positional encoding + MLP\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.div_term = torch.exp(torch.arange(0, dim).float() * (-torch.log(torch.tensor(10000.0)) / dim))\n",
    "        self.fc1 = nn.Linear(2 * dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "    def forward(self, x):\n",
    "        # x: [B, seq_len]\n",
    "        sine = torch.sin(x[:, :, None] * self.div_term[None, None, :].to(x.device))\n",
    "        cosine = torch.cos(x[:, :, None] * self.div_term[None, None, :].to(x.device))\n",
    "        encoding = torch.cat([sine, cosine], dim=-1)\n",
    "        encoding = F.relu(self.fc1(encoding))\n",
    "        encoding = self.fc2(encoding)\n",
    "        return encoding\n",
    "class FluxTransformerDecoder(nn.Module):\n",
    "    def __init__(self, n_physical_param=10, n_wavelength=602,\n",
    "                 d_model=128, nhead=8, num_layers=4, learnedPE=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = n_wavelength\n",
    "        self.learnedPE = learnedPE\n",
    "        # Memory embedding\n",
    "        self.encoder_proj = SinusoidalMLPPositionalEmbedding(d_model)\n",
    "        self.physical_param_embd = nn.Parameter(torch.randn(1, n_physical_param, d_model))\n",
    "        self.memory_ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        # Query embedding\n",
    "        if learnedPE:\n",
    "            self.query = nn.Parameter(torch.randn(1, n_wavelength, d_model))\n",
    "        else:\n",
    "            self.query_embd = SinusoidalMLPPositionalEmbedding(d_model)\n",
    "            grid = torch.linspace(0, 1, steps=n_wavelength)[None, :]\n",
    "            self.register_buffer(\"grid\", grid)\n",
    "        # Transformer decoder layers\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            batch_first=True,\n",
    "            norm_first=True  # pre-layernorm\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=num_layers,\n",
    "            norm=nn.LayerNorm(d_model)  # post-norm after final layer\n",
    "        )\n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(d_model, 1)\n",
    "    def forward(self, physical_param):\n",
    "        \"\"\"\n",
    "        physical_param: [B, n_physical_param]\n",
    "        Returns: [B, n_wavelength]\n",
    "        \"\"\"\n",
    "        B = physical_param.shape[0]\n",
    "        # Memory: embed + positional + scale\n",
    "        memory = self.encoder_proj(physical_param) + self.physical_param_embd  # [B, n_physical_param, d_model]\n",
    "        memory = memory * (self.d_model ** 0.5)  # scale\n",
    "        memory = self.memory_ff(memory)\n",
    "        # Query / target\n",
    "        if self.learnedPE:\n",
    "            tgt = self.query.repeat(B, 1, 1)\n",
    "        else:\n",
    "            tgt = self.query_embd(self.grid).repeat(B, 1, 1)\n",
    "        # Transformer decoder\n",
    "        decoded = self.decoder(tgt, memory)  # [B, seq_len, d_model]\n",
    "        # Project to scalar\n",
    "        out = self.output_proj(decoded)  # [B, seq_len, 1]\n",
    "        return out.squeeze(-1)           # [B, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb32e65b-6bed-4a84-9354-21a72ce233dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 13\n",
      "running\n",
      "mean_std_dict: {'time_mean': 2764800.0, 'time_std': 1396503.0612211346, 'descriptor_mean': tensor([4.9626e-01, 5.0165e-01, 5.0399e-01, 4.9725e-01, 1.6165e+08, 2.1548e+09,\n",
      "        1.0123e+33, 2.5744e+32, 7.8069e+33], dtype=torch.float64), 'descriptor_std': tensor([2.8809e-01, 2.8790e-01, 2.8765e-01, 2.8677e-01, 8.2336e+07, 7.7078e+08,\n",
      "        5.6994e+32, 1.4018e+32, 4.5137e+33], dtype=torch.float64), 'fluxes_mean': tensor(37.3654, dtype=torch.float64), 'fluxes_std': tensor(4.6562, dtype=torch.float64)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from dataloader import *\n",
    "from tqdm import tqdm  # To show progress bar during training\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import sys\n",
    "from support_funcs1 import *\n",
    "from support_funcs2 import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"line 13\")\n",
    "mean_std_dict = torch.load('normalization_stats.pt')\n",
    "\n",
    "print(\"running\")\n",
    "print(\"mean_std_dict: \"+str(mean_std_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cec490-ae5e-44a3-bbad-cb08cf3b7e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training sample: 2\n",
      "created test and train loaders\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_data = torch.load(\"preprocessed_small_spectra.pt\")\n",
    "all_sample_ids = sorted({entry['sample_id'] for entry in all_data})\n",
    "\n",
    "train_sample_ids = all_sample_ids\n",
    "\n",
    "print(\"length of training sample: \"+str(len(train_sample_ids)))\n",
    "\n",
    "\n",
    "train_data = [entry for entry in all_data if entry['sample_id'] in train_sample_ids]\n",
    "#test_data  = [entry for entry in all_data if entry['sample_id'] in train_sample_ids]\n",
    "\n",
    "from dataloader import NormalizeSpectralData, FastSupernovaDataset\n",
    "mean_std_dict = torch.load('normalization_stats.pt')\n",
    "transform = NormalizeSpectralData(mean_std_dict)\n",
    "train_dataset = FastSupernovaDataset(samples=train_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True,  drop_last=True)\n",
    "\n",
    "\n",
    "print(\"created test and train loaders\")\n",
    "N_wavelengths = 602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a92882c-93e2-4121-9f96-1b3f52b6b3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: FluxTransformerDecoder(\n",
      "  (encoder_proj): SinusoidalMLPPositionalEmbedding(\n",
      "    (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (memory_ff): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (query_embd): SinusoidalMLPPositionalEmbedding(\n",
      "    (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (output_proj): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, scheduler, epochs=10):\n",
    "    ep = 1.0E-6\n",
    "    model.train()\n",
    "    filter_prof_dir = 'filter_profs/'\n",
    "    filters = {'u': 'SLOAN_SDSS.u', 'g': 'SLOAN_SDSS.g', 'r': 'SLOAN_SDSS.r', 'i': 'SLOAN_SDSS.i', 'z': 'SLOAN_SDSS.z'}\n",
    "    band_passes = {}\n",
    "    fluxes_mean = mean_std_dict['fluxes_mean'].to(torch.float64).to(device)\n",
    "    fluxes_std = mean_std_dict['fluxes_std'].to(torch.float64).to(device)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # Only print occasionally for progress\n",
    "            descriptor = batch['descriptor'].float().to(device)\n",
    "            time = batch['time'].unsqueeze(1).float().to(device)\n",
    "            fluxes = batch['flux'].float().to(device)\n",
    "            wav = batch['wav'].float().to(device) \n",
    "            input_data = torch.cat((descriptor, time), dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            #output = torch.clamp(model(input_data), -3, 3)\n",
    "            output = model(input_data)\n",
    "            spec_pred = output.to(torch.float64)\n",
    "            spec_true = fluxes.to(torch.float64)\n",
    "            \n",
    "            '''\n",
    "            mag_loss = torch.log10(criterion( torch.sum(10.**(spec_pred*fluxes_std + fluxes_mean)), \n",
    "                                              torch.sum(10.**(spec_true*fluxes_std + fluxes_mean)) ))'''\n",
    "            \n",
    "\n",
    "            loss = criterion(fluxes, output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        scheduler.step(epoch_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out_eval = model(input_data)\n",
    "    model.train()\n",
    "    out_train = model(input_data)\n",
    "    return model\n",
    "\n",
    "# Set up model, loss, optimizer\n",
    "model = FluxTransformerDecoder()  # PyTorch 1.6+: beta=1.0 (or try 0.5, 2.0)\n",
    "#model = nn.Sequential(nn.Linear(10, 512), nn.ReLU(), nn.Linear(512, N_wavelengths)).to(device)\n",
    "# Set up optimizer\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(\"model: \"+str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6753467-6362-49c5-82a9-c4b3a7e5a174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running here\n",
      "Epoch [1/100], Loss: 5.5744\n",
      "Epoch [2/100], Loss: 0.3197\n",
      "Epoch [3/100], Loss: 0.6976\n",
      "Epoch [4/100], Loss: 0.1558\n",
      "Epoch [5/100], Loss: 0.0703\n",
      "Epoch [6/100], Loss: 0.1808\n",
      "Epoch [7/100], Loss: 0.1037\n",
      "Epoch [8/100], Loss: 0.0327\n",
      "Epoch [9/100], Loss: 0.0519\n",
      "Epoch [10/100], Loss: 0.0604\n",
      "Epoch [11/100], Loss: 0.0337\n",
      "Epoch [12/100], Loss: 0.0216\n",
      "Epoch [13/100], Loss: 0.0281\n",
      "Epoch [14/100], Loss: 0.0291\n",
      "Epoch [15/100], Loss: 0.0192\n",
      "Epoch [16/100], Loss: 0.0222\n",
      "Epoch [17/100], Loss: 0.0227\n",
      "Epoch [18/100], Loss: 0.0201\n",
      "Epoch [19/100], Loss: 0.0174\n",
      "Epoch [20/100], Loss: 0.0190\n",
      "Epoch [21/100], Loss: 0.0200\n",
      "Epoch [22/100], Loss: 0.0179\n",
      "Epoch [23/100], Loss: 0.0165\n",
      "Epoch [24/100], Loss: 0.0178\n",
      "Epoch [25/100], Loss: 0.0183\n",
      "Epoch [26/100], Loss: 0.0175\n",
      "Epoch [27/100], Loss: 0.0168\n",
      "Epoch [28/100], Loss: 0.0174\n",
      "Epoch [29/100], Loss: 0.0173\n",
      "Epoch [30/100], Loss: 0.0171\n",
      "Epoch [31/100], Loss: 0.0163\n",
      "Epoch [32/100], Loss: 0.0170\n",
      "Epoch [33/100], Loss: 0.0165\n",
      "Epoch [34/100], Loss: 0.0170\n",
      "Epoch [35/100], Loss: 0.0169\n",
      "Epoch [36/100], Loss: 0.0162\n",
      "Epoch [37/100], Loss: 0.0173\n",
      "Epoch [38/100], Loss: 0.0160\n",
      "Epoch [39/100], Loss: 0.0169\n",
      "Epoch [40/100], Loss: 0.0167\n",
      "Epoch [41/100], Loss: 0.0161\n",
      "Epoch [42/100], Loss: 0.0176\n",
      "Epoch [43/100], Loss: 0.0168\n",
      "Epoch [44/100], Loss: 0.0165\n",
      "Epoch [45/100], Loss: 0.0160\n",
      "Epoch [46/100], Loss: 0.0158\n",
      "Epoch [47/100], Loss: 0.0161\n",
      "Epoch [48/100], Loss: 0.0162\n",
      "Epoch [49/100], Loss: 0.0155\n",
      "Epoch [50/100], Loss: 0.0172\n",
      "Epoch [51/100], Loss: 0.0156\n",
      "Epoch [52/100], Loss: 0.0166\n",
      "Epoch [53/100], Loss: 0.0154\n",
      "Epoch [54/100], Loss: 0.0154\n",
      "Epoch [55/100], Loss: 0.0151\n",
      "Epoch [56/100], Loss: 0.0150\n",
      "Epoch [57/100], Loss: 0.0148\n",
      "Epoch [58/100], Loss: 0.0157\n",
      "Epoch [59/100], Loss: 0.0152\n",
      "Epoch [60/100], Loss: 0.0159\n",
      "Epoch [61/100], Loss: 0.0155\n",
      "Epoch [62/100], Loss: 0.0152\n",
      "Epoch [63/100], Loss: 0.0140\n",
      "Epoch [64/100], Loss: 0.0144\n",
      "Epoch [65/100], Loss: 0.0138\n",
      "Epoch [66/100], Loss: 0.0140\n",
      "Epoch [67/100], Loss: 0.0135\n",
      "Epoch [68/100], Loss: 0.0140\n",
      "Epoch [69/100], Loss: 0.0132\n",
      "Epoch [70/100], Loss: 0.0131\n",
      "Epoch [71/100], Loss: 0.0131\n",
      "Epoch [72/100], Loss: 0.0130\n",
      "Epoch [73/100], Loss: 0.0132\n",
      "Epoch [74/100], Loss: 0.0121\n",
      "Epoch [75/100], Loss: 0.0123\n",
      "Epoch [76/100], Loss: 0.0124\n",
      "Epoch [77/100], Loss: 0.0117\n",
      "Epoch [78/100], Loss: 0.0118\n",
      "Epoch [79/100], Loss: 0.0111\n",
      "Epoch [80/100], Loss: 0.0117\n",
      "Epoch [81/100], Loss: 0.0111\n",
      "Epoch [82/100], Loss: 0.0114\n",
      "Epoch [83/100], Loss: 0.0110\n",
      "Epoch [84/100], Loss: 0.0109\n",
      "Epoch [85/100], Loss: 0.0106\n",
      "Epoch [86/100], Loss: 0.0106\n",
      "Epoch [87/100], Loss: 0.0108\n",
      "Epoch [88/100], Loss: 0.0106\n",
      "Epoch [89/100], Loss: 0.0102\n",
      "Epoch [90/100], Loss: 0.0100\n",
      "Epoch [91/100], Loss: 0.0105\n",
      "Epoch [92/100], Loss: 0.0103\n",
      "Epoch [93/100], Loss: 0.0104\n",
      "Epoch [94/100], Loss: 0.0102\n",
      "Epoch [95/100], Loss: 0.0104\n",
      "Epoch [96/100], Loss: 0.0100\n",
      "Epoch [97/100], Loss: 0.0100\n",
      "Epoch [98/100], Loss: 0.0099\n",
      "Epoch [99/100], Loss: 0.0099\n",
      "Epoch [100/100], Loss: 0.0102\n"
     ]
    }
   ],
   "source": [
    "print(\"running here\")\n",
    "\n",
    "# Add a scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=8, factor=0.5)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Usage\n",
    "model = train_model(model, train_loader, criterion, optimizer, scheduler, epochs=100)\n",
    "\n",
    "\n",
    "#save the model\n",
    "mkdir(\"Saved Model/\")\n",
    "torch.save(model.state_dict(), \"Saved Model/NN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b636a3b-5fb0-4ddf-9bb6-d167f8359ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586979af-28eb-4389-8aa0-789f884c8554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb94d50-862f-4dcc-a985-7fc86d447300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data: tensor([[-0.5805,  1.0007, -0.4905,  0.0273,  1.0156,  0.9762, -0.0243,  1.5730,\n",
      "         -0.9920, -1.4539],\n",
      "        [-1.5312, -0.3580, -0.2951, -0.5497,  0.0737, -1.3751,  1.5465, -1.0589,\n",
      "          1.5441, -1.5158]], device='cuda:0')\n",
      "predicted output[0:15]: tensor([0.2218, 0.2218, 0.2218, 0.2218, 0.2218, 0.2218, 0.2218, 0.2218, 0.2218,\n",
      "        0.2218, 0.2218, 0.2218, 0.2217, 0.2217, 0.2217], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "loss: tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from astropy.constants import c\n",
    "filter_prof_dir = 'filter_profs/'\n",
    "# After model.eval()\n",
    "model.eval() #<--- UNCOMMENTING THIS CODE MAKES EVERYTHING GO TO HELL.. WHY THE HELL \n",
    "for i, batch in enumerate(train_loader):\n",
    "    # Input prep as before\n",
    "    descriptor = batch['descriptor'].float().to(device)\n",
    "    time = batch['time'].unsqueeze(1).float().to(device)\n",
    "\n",
    "    wav = batch['wav'].cpu().numpy() \n",
    "    fluxes = batch['flux'].float().to(device)\n",
    "    sample_id = batch['sample_id']\n",
    "\n",
    "    input_data = torch.cat((descriptor, time), dim=1)\n",
    "    output = model(input_data)\n",
    "    print(\"input data: \"+str(input_data))\n",
    "    print(\"predicted output[0:15]: \"+str(output[0, :15]))\n",
    "    loss = criterion(fluxes, output)\n",
    "    print(\"loss: \"+str(loss))\n",
    "    # Denormalize Chebyshev coefficients for FIRST sample in batch (for demo)\n",
    "    norm_stats = mean_std_dict\n",
    "    fluxes_mean = norm_stats['fluxes_mean'].float().to(device)\n",
    "    fluxes_std = norm_stats['fluxes_std'].float().to(device)\n",
    "\n",
    "    output = output.to(torch.float64)\n",
    "    fluxes = fluxes.to(torch.float64)\n",
    "    spec_pred = 10.**(output * fluxes_std + fluxes_mean).cpu().detach().numpy()\n",
    "    spec_true = 10.**(fluxes * fluxes_std + fluxes_mean).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"spec_pred shape: \"+str(spec_pred.shape))\n",
    "    #print(\"spec_true shape: \"+str(spec_true.shape))\n",
    "\n",
    "    time_norm = batch['time']         # [batch]            # normalized time (tensor)\n",
    "    desc_norm = batch['descriptor']   # [batch, 9]         # normalized descriptor (tensor)\n",
    "\n",
    "    # Get mean/std as numpy arrays or tensors of compatible type\n",
    "    time_mean = float(mean_std_dict['time_mean'])\n",
    "    time_std = float(mean_std_dict['time_std'])\n",
    "    descriptor_mean = mean_std_dict['descriptor_mean'].cpu().numpy()  # [9]\n",
    "    descriptor_std = mean_std_dict['descriptor_std'].cpu().numpy()    # [9]\n",
    "\n",
    "    # Unnormalize time and descriptors for the FIRST sample in the batch:\n",
    "    #    (if you want all samples, use a for loop over the batch)\n",
    "    time_unnorm = time_norm[0].cpu().numpy() * time_std + time_mean\n",
    "    time_d = str(round(time_unnorm/86400, 3))\n",
    "    desc_unnorm = desc_norm[0].cpu().numpy() * descriptor_std + descriptor_mean\n",
    "\n",
    "    #print(f\"Batch {i} -- un-normalized time (first in batch):\", time_unnorm)\n",
    "    #print(f\"Batch {i} -- un-normalized descriptor (first in batch):\\n\", desc_unnorm)\n",
    "\n",
    "    # --- Plot as before ---\n",
    "    plt, _, _ = get_pretty_plot()\n",
    "    plt.scatter(wav[0], spec_true[0], label='Ground Truth', color = space_colors[0])\n",
    "    plt.plot(wav[0], spec_pred[0], label='Predicted\\n('+f\"{loss.item():04.3f}\"+\")\", linewidth=4, color = space_colors[1])\n",
    "    plt.xlabel(r\"Wavelength ($\\AA$)\", fontsize=35)\n",
    "    plt.ylabel(\"Flux\", fontsize=35)\n",
    "    plt.title('Time_' + str(time_unnorm/86400)+\"|Sample: \"+str(sample_id[0]), fontsize=35)\n",
    "    #plt.ylim([0, 1.0E39])\n",
    "    plt.legend(fontsize=25)\n",
    "    mkdir(\"Predicted Train_small/\")\n",
    "    plt.savefig(f\"Predicted Train_small/\"+time_d+\"_\"+str(sample_id[0])+\".pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt, _, _ = get_pretty_plot()\n",
    "    plt.plot(wav[0], spec_true[0], label='Ground Truth', color = space_colors[0], linewidth = 4)\n",
    "    plt.plot(wav[0], spec_pred[0], label='Predicted\\n('+f\"{loss.item():04.3f}\"+\")\", linewidth=4, color = space_colors[1])\n",
    "    plt.xlabel(r\"Wavelength ($\\AA$)\", fontsize=35)\n",
    "    plt.ylabel(\"Flux\", fontsize=35)\n",
    "    plt.title('Time_' + time_d+\"|Sample: \"+str(sample_id[0]), fontsize=35)\n",
    "    #plt.ylim([0, 1.0E39])\n",
    "    plt.legend(fontsize=25)\n",
    "    mkdir(\"Predicted Train_small/\")\n",
    "    plt.savefig(f\"Predicted Train_small/\"+time_d+\"_\"+str(sample_id[0])+\"_p.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    plt, _, _ = get_pretty_plot()\n",
    "    plt.scatter(wav[0], spec_true[0], label='Ground Truth', color = space_colors[0])\n",
    "    plt.scatter(wav[0], spec_pred[0], label='Predicted\\n('+f\"{loss.item():04.3f}\"+\")\", color = space_colors[1])\n",
    "    plt.xlabel(r\"Wavelength ($\\AA$)\", fontsize=35)\n",
    "    plt.ylabel(\"Flux\", fontsize=35)\n",
    "    plt.title('Time_' + str(time_unnorm/86400)+\"|Sample: \"+str(sample_id[0]), fontsize=35)\n",
    "    #plt.ylim([0, 1.0E39])\n",
    "    plt.legend(fontsize=25)\n",
    "    mkdir(\"Predicted Train_small/\")\n",
    "    plt.savefig(f\"Predicted Train_small/\"+time_d+\"_\"+str(sample_id[0])+\"_s.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "            #calculate photometry in ugriz filters using the predicted and true spectra\n",
    "    true_mags = []\n",
    "    pred_mags = []\n",
    "    del_mags = []\n",
    "    filts = []\n",
    "    filters = {'u': 'SLOAN_SDSS.u', 'g': 'SLOAN_SDSS.g', 'r': 'SLOAN_SDSS.r', 'i': 'SLOAN_SDSS.i', 'z': 'SLOAN_SDSS.z'}\n",
    "    for fil in filters:\n",
    "        #read in the bandpass in this filter\n",
    "        filter_data = np.loadtxt(filter_prof_dir+\"/\"+str(filters[fil])+\".dat\")\n",
    "        filter_wavs = filter_data[:, 0]\n",
    "        filter_transmission = filter_data[:, 1]\n",
    "\n",
    "\n",
    "        #calculate the photometric point in this filter\n",
    "        speed_of_light = c\n",
    "        #spectra from sedona are outputted as L_nu, right? So total luminosity at a given \\nu\n",
    "        #I need to divide it by 4*pi*(1 parsec)**2 so it is flux, rather than luminosity\n",
    "        d = (10*u.parsec).to(u.cm).value\n",
    "        denom = 4*np.pi*d**2.0\n",
    "        true_mag = compute_photometry(wav[0], spec_true[0]/denom, filter_wavs, filter_transmission)\n",
    "        pred_mag = compute_photometry(wav[0], spec_pred[0]/denom, filter_wavs, filter_transmission)\n",
    "        del_mag = np.abs(true_mag-pred_mag)\n",
    "        del_mags.append(del_mag)\n",
    "        true_mags.append(true_mag)\n",
    "        pred_mags.append(pred_mag)\n",
    "        filts.append(fil)\n",
    "\n",
    "\n",
    "    true_mags = np.asarray(true_mags)\n",
    "    pred_mags = np.asarray(pred_mags)\n",
    "    filts = np.asarray(filts)\n",
    "    del_mags = np.asarray(del_mags)\n",
    "    tow = np.asarray([true_mags, pred_mags, del_mags, filts]).T\n",
    "\n",
    "    out_file = \"Predicted Train_small/\"+time_d+\"_\"+str(sample_id[0])+\"_phot.txt\"\n",
    "    rm(out_file)\n",
    "    write_to_file(out_file, '# True_mag pred_mag del_mag filt\\n', append = False)\n",
    "    write_to_file(out_file, tow, append = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af45ac-da58-4e76-82cf-55979c68e295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d1aab-167f-4059-ad7b-b50ad26af24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667842e-1e27-4c13-a533-1d17a137ab6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91dd1ef-136e-4f01-9201-bd7d20818b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sedona_venv]",
   "language": "python",
   "name": "conda-env-.conda-sedona_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
